{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = {'batchSize':64, \n",
    "       'beta1':0.5, \n",
    "       'cuda':False, \n",
    "       'dataroot':'./celebA/', \n",
    "       'dataset':'celebA', \n",
    "       'imageSize':64, \n",
    "       'lr':0.0002, \n",
    "       'manualSeed':None,\n",
    "       'outf':'./checkpoints',\n",
    "       'ndf':64, \n",
    "       'netD':'', \n",
    "       'netG':'', \n",
    "       'ngf':64, \n",
    "       'ngpu':1, \n",
    "       'niter':25, \n",
    "       'nz':100, \n",
    "       'm': 20,\n",
    "       'workers':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=opt['dataroot'], transform=transforms.Compose([\n",
    "                                   transforms.Scale(64),\n",
    "                                   transforms.CenterCrop(64),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64,\n",
    "                                         shuffle=True, num_workers=int(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngpu = int(opt['ngpu'])\n",
    "nz = int(opt['nz'])\n",
    "ngf = int(opt['ngf'])\n",
    "ndf = int(opt['ndf'])\n",
    "nc = 3\n",
    "m = int(opt['m'])\n",
    "fixed_noise = Variable(torch.FloatTensor(50, nz, 1, 1).normal_(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    return\n",
    "\n",
    "class gen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gen, self).__init__()\n",
    "        self._gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self._gen(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(enc, self).__init__()\n",
    "        self._enc = nn.Sequential(\n",
    "            # 3 x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # ndf x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)\n",
    "            # (ndf*4) x 8 x 8\n",
    "        )\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self._enc(input)\n",
    "        return output.view(-1,1)\n",
    "\n",
    "    \n",
    "class dec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dec, self).__init__()\n",
    "        self._dec = nn.Sequential(\n",
    "            # (ndf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ndf * 4, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # (ndf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ndf * 2, ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.ReLU(True),\n",
    "            # (ndf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ndf, 3, 4, 2, 1, bias=False),\n",
    "            # (3) x 64 x 64\n",
    "        )\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self._dec(input)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class autoenc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoenc, self).__init__()\n",
    "        self._enc = enc()\n",
    "        self._dec = dec()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self._enc(input)\n",
    "        output = output.view(-1,ndf*4, 8, 8)\n",
    "        output = self._dec(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netG = gen()\n",
    "netD = autoenc()\n",
    "\n",
    "if opt['cuda']:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    fixed_noise = fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG.apply(weights_init)\n",
    "if opt['netG'] != '':\n",
    "    netG.load_state_dict(torch.load(opt['netG']))\n",
    "    \n",
    "netD.apply(weights_init)\n",
    "if opt['netD'] != '':\n",
    "    netD.load_state_dict(torch.load(opt['netD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "if opt['cuda']:\n",
    "    criterion.cuda()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt['lr'], betas=(opt['beta1'], 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt['lr'], betas=(opt['beta1'], 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    netG.zero_grad()\n",
    "    netD.zero_grad()\n",
    "    return\n",
    "\n",
    "def D(input):\n",
    "    x_rec = netD(input)\n",
    "    output = torch.mean(torch.sum((input - x_rec)**2, 1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(opt['niter']):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        X, _ = data\n",
    "        X = Variable(X)\n",
    "        \n",
    "        batch = X.size()[0]\n",
    "        noise = Variable(torch.randn(batch, nz, 1, 1))\n",
    "        noise.data.normal_(0,1)\n",
    "        \n",
    "        if opt['cuda']:\n",
    "            X = X.cuda()\n",
    "            noise = noise.cuda()\n",
    "        \n",
    "        # Dicriminator\n",
    "        G_sample = netG(noise)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        # EBGAN D loss. D_real and D_fake is energy, i.e. a number\n",
    "        D_loss = D_real + f.relu(m - D_fake)\n",
    "        \n",
    "        # Reuse D_fake for generator loss\n",
    "        D_loss.backward()\n",
    "        optimizerD.step()\n",
    "        reset_grad()\n",
    "        \n",
    "        # Generator\n",
    "        G_sample = netG(noise)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        G_loss = D_fake\n",
    "        \n",
    "        G_loss.backward()\n",
    "        optimizerG.step()\n",
    "        reset_grad()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print('D_loss: ', D_loss.data[0], ' , G_loss: ', G_loss.data[0])\n",
    "            break\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt['outf'], epoch))\n",
    "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt['outf'], epoch))\n",
    "        fake_images = netG(fixed_noise)\n",
    "        vutils.save_image(fake_images.data,'%s/fake_samples_epoch_%03d.png' % (opt['outf'], epoch),\n",
    "                          nrow=5, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
